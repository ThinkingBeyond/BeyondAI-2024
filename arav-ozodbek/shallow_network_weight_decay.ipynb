{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBtpbx9iiJNGIgdBNND0qO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install required packages\n","\n","!pip install tensorflow==2.18.0\n","!pip install keras==3.7.0\n","!pip install torch==2.5.1\n","!pip install torchvision==0.20.1\n","\n","!pip install numpy==2.0.2\n","!pip install scipy==1.14.1\n","!pip install pandas==2.2.3\n","\n","!pip install scikit-learn==1.5.2\n","\n","!pip install matplotlib==3.9.2\n","\n","!pip install joblib==1.4.2\n","!pip install python-dateutil==2.9.0.post0\n","\n","!pip install sympy==1.13.1\n","!pip install opt-einsum==3.4.0\n","\n","!pip install tensorboard==2.18.0\n","!pip install protobuf==5.29.0\n","!pip install threadpoolctl==3.5.0\n","!pip install packaging==24.2\n"],"metadata":{"id":"r2Rs58Nhz7ya"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#1. Import Necessary Libraries"],"metadata":{"id":"qld_18pTOmk5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQAUEgUgOdtj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras.regularizers import l2"]},{"cell_type":"markdown","source":["* numpy: For numerical operations and dataset creation.\n","* matplotlib.pyplot: For visualizing loss and accuracy trends.\n","* train_test_split: Splits the dataset into training and testing subsets.\n","* Sequential, Dense: *Tools to build a shallow neural network*.\n","* Adam: Optimizer for efficient training.\n","* l2: *Regularizer for weight decay, which penalizes large weights*."],"metadata":{"id":"HBZbhe5gOkvB"}},{"cell_type":"markdown","source":["#2. Generate Synthetic Dataset"],"metadata":{"id":"08rP-5_CQC_U"}},{"cell_type":"code","source":["np.random.seed(42)\n","n_samples = 100  # Larger dataset for better training\n","X = np.random.uniform(-1, 1, size=(n_samples, 1))\n","y = (np.sin(2 * np.pi * X).ravel() + 0.7 * np.random.normal(size=n_samples)) > 0  # Binary classification"],"metadata":{"id":"LNpZBsbpO3h5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* X: Input features uniformly sampled between *-1 and 1*.\n","* y: Binary labels generated by thresholding a sine function with added Gaussian noise (*ùúé= 0.7*)."],"metadata":{"id":"sSmD72OPO5Qy"}},{"cell_type":"markdown","source":["#3. Split Data into Training and Testing Sets"],"metadata":{"id":"yyya8r5DQIit"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"H3CYnuDBO_5A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Set**: *80% of the dataset used for model training*.\n","\n","**Testing Set**: *20% reserved for evaluating the model's performance*."],"metadata":{"id":"DIkNCU6aPBn7"}},{"cell_type":"markdown","source":["#4. Experiment Configurations"],"metadata":{"id":"tTODI9JNQLfD"}},{"cell_type":"code","source":["epoch_counts = [250, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500]  # Epoch range\n","weight_decay_values = [0.0, 0.01, 0.1, 0.5, 1.0]  # Different weight decay values\n","hidden_layer_size = 50  # Fixed number of neurons in the hidden layer"],"metadata":{"id":"BwlYGQO_PFKL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* epoch_counts: Range of epochs for analyzing training duration effects.\n","* weight_decay_values: Specifies levels of weight decay (*L2 regularization strength*).\n","* hidden_layer_size: Defines the complexity of the shallow neural network."],"metadata":{"id":"g6SU5fhTPIBP"}},{"cell_type":"markdown","source":["#5. Initialize Results Storage"],"metadata":{"id":"yzk_7zfQQOsq"}},{"cell_type":"code","source":["results = {}"],"metadata":{"id":"f962U4o1PK03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Stores training and testing **losses** and **accuracies** for each weight decay value.\n"],"metadata":{"id":"q7lQQZEbPM8q"}},{"cell_type":"markdown","source":["#6. Iterate Over Weight Decay Values and Epoch Configurations"],"metadata":{"id":"qJGOiH72QRxm"}},{"cell_type":"code","source":["for weight_decay in weight_decay_values:\n","    train_losses, test_losses = [], []\n","    train_accuracies, test_accuracies = [], []\n","\n","    for epochs in epoch_counts:\n","        # Build the model\n","        model = Sequential([\n","            Dense(hidden_layer_size, input_dim=1, activation='relu', kernel_regularizer=l2(weight_decay)),\n","            Dense(1, activation='sigmoid', kernel_regularizer=l2(weight_decay))\n","        ])\n","\n","        # Compile the model\n","        model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","        # Train the model\n","        model.fit(X_train, y_train, epochs=epochs, verbose=0, batch_size=16)\n","\n","        # Evaluate the model\n","        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n","        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n","\n","        # Log the results\n","        train_losses.append(train_loss)\n","        test_losses.append(test_loss)\n","        train_accuracies.append(train_acc)\n","        test_accuracies.append(test_acc)\n","\n","    # Store results for the current weight decay value\n","    results[weight_decay] = {\n","        'train_losses': train_losses,\n","        'test_losses': test_losses,\n","        'train_accuracies': train_accuracies,\n","        'test_accuracies': test_accuracies\n","    }"],"metadata":{"id":"YrTk_TCQPOmY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Model Creation:\n","\n","* A shallow neural network is created with **L2 regularization** applied to each dense layer.\n","* The weight decay strength is determined by the current weight_decay value.\n","2. Compilation:\n","\n","* **Optimizer**: Adam with a *learning rate of 0.01*.\n","* **Loss**: Binary Crossentropy for binary classification.\n","* **Metrics**: *Accuracy is tracked during evaluation*.\n","3. Training and Evaluation:\n","\n","* The model is **trained** for each epoch configuration.\n","* Training and testing **losses and accuracies** are evaluated and stored.\n","4. Result Storage:\n","\n","* Results for each **weight decay value** are stored, including **losses and accuracies**."],"metadata":{"id":"Sp7Cov1LPQf5"}},{"cell_type":"markdown","source":["#7. Visualize Loss Results"],"metadata":{"id":"Isi_7G2AQVCd"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","for weight_decay in weight_decay_values:\n","    plt.plot(epoch_counts, results[weight_decay]['test_losses'], label=f\"Test Loss (Weight Decay={weight_decay})\", marker='o')\n","    plt.plot(epoch_counts, results[weight_decay]['train_losses'], linestyle='--', label=f\"Train Loss (Weight Decay={weight_decay})\")\n","\n","plt.xlabel('Number of Epochs')\n","plt.ylabel('Loss (Binary Crossentropy)')\n","plt.title('Effect of Weight Decay Regularization on Loss')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"id":"1nVy44qpPeeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**X-axis**: Number of epochs.\n","\n","**Y-axis**: Binary crossentropy loss (*train and test*).\n","\n","Curves:\n","\n","* **Solid lines** for test loss.\n","* **Dashed lines** for training loss.\n"],"metadata":{"id":"RC9_jBO1PfbD"}},{"cell_type":"markdown","source":["#8. Visualize Accuracy Results"],"metadata":{"id":"YWxO1smoQYpt"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","for weight_decay in weight_decay_values:\n","    plt.plot(epoch_counts, results[weight_decay]['test_accuracies'], label=f\"Test Accuracy (Weight Decay={weight_decay})\", marker='o')\n","    plt.plot(epoch_counts, results[weight_decay]['train_accuracies'], linestyle='--', label=f\"Train Accuracy (Weight Decay={weight_decay})\")\n","\n","plt.xlabel('Number of Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Effect of Weight Decay Regularization on Accuracy')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"id":"jON8bAPkPlq3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**X-axis**: Number of epochs.\n","\n","**Y-axis**: Accuracy (train and test).\n","\n","**Curves**:\n","\n","* **Solid lines** for *test accuracy*.\n","* **Dashed lines** for *training accuracy*."],"metadata":{"id":"qgntBhBWPmnO"}},{"cell_type":"markdown","source":["#Key Observations\n","**Weight Decay Impact**:\n","\n","* *Reduces overfitting* at moderate levels (e.g.,*ùõº = 0.1*).\n","* **Excessive weight decay** (e.g.,*ùõº = 1.0*) may cause **underfitting**, increasing test loss and reducing accuracy.\n","\n","**Double Descent**:\n","\n","* Loss and accuracy trends reveal **epoch-wise double descent behavior** for various weight decay configurations."],"metadata":{"id":"MA59gM-VPtvN"}}]}