import os
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from clifford import Cl
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

#train
def load_split_data(split_dir, split_name):
    split_path = "/content/sample_data/nao_dataset/train/LTrain_x.csv"
    data = pd.read_csv(split_path)

    positions = data[['Px', 'Py', 'Pz']].values
    rotations = data[['Rx', 'Ry', 'Rz']].values

    # Define custom labels based on position ('Px')
    data['label'] = (data['Px'] > 0).astype(int)
    labels = data['label'].values

    # Convert to tensors
    positions_tensor = torch.tensor(positions, dtype=torch.float32)
    rotations_tensor = torch.tensor(rotations, dtype=torch.float32)
    labels_tensor = torch.tensor(labels, dtype=torch.long)

    return positions_tensor, rotations_tensor, labels_tensor

#test
def load_test_data(test_file):
    test_path = "/content/sample_data/nao_dataset/test/LTest_x.csv"
    data = pd.read_csv(test_path)

    positions = data[['Px', 'Py', 'Pz']].values
    rotations = data[['Rx', 'Ry', 'Rz']].values
    labels = (data['Px'] > 0).astype(int).values

    positions_tensor = torch.tensor(positions, dtype=torch.float32)
    rotations_tensor = torch.tensor(rotations, dtype=torch.float32)
    labels_tensor = torch.tensor(labels, dtype=torch.long)

    return positions_tensor, rotations_tensor, labels_tensor

#validation
def load_val_data(val_file):
    val_path = "/content/sample_data/nao_dataset/val/LVal_x.csv"
    data = pd.read_csv(val_path)

    positions = data[['Px', 'Py', 'Pz']].values
    rotations = data[['Rx', 'Ry', 'Rz']].values

    labels = (data['Px'] > 0).astype(int).values

    positions_tensor = torch.tensor(positions, dtype=torch.float32)
    rotations_tensor = torch.tensor(rotations, dtype=torch.float32)
    labels_tensor = torch.tensor(labels, dtype=torch.long)

    return positions_tensor, rotations_tensor, labels_tensor

dataset_dir = "/content/sample_data/nao_dataset"
train_positions, train_rotations, train_labels = load_split_data(dataset_dir, 'train')
val_positions, val_rotations, val_labels = load_split_data(dataset_dir, 'val')
test_positions, test_rotations, test_labels = load_split_data(dataset_dir, 'test')

train_features = torch.cat((train_positions, train_rotations), dim=1)
val_features = torch.cat((val_positions, val_rotations), dim=1)
test_features = torch.cat((test_positions, test_rotations), dim=1)

# Create PyTorch datasets and dataloaders
from torch.utils.data import TensorDataset, DataLoader

train_dataset = TensorDataset(train_features, train_labels)
val_dataset = TensorDataset(val_features, val_labels)
test_dataset = TensorDataset(test_features, test_labels)

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)


# Step 6: Define GeoLayer using Clifford Algebra
layout, blades = Cl(3)
e1, e2, e3 = blades['e1'], blades['e2'], blades['e3']

class GeoLayer(nn.Module):
    def __init__(self):
        super(GeoLayer, self).__init__()

    def forward(self, positions, rotations):
        # Convert positions and rotations to multivectors using Clifford algebra
        scalar_features = []
        for i in range(positions.size(0)):
            # Convert inputs to multivectors (positions and rotations as geometric vectors)
            p = e1 * positions[i, 0] + e2 * positions[i, 1] + e3 * positions[i, 2]
            r = e1 * rotations[i, 0] + e2 * rotations[i, 1] + e3 * rotations[i, 2]

            # Combine position and rotation information
            geo_vector = p + r

            # Calculate the magnitude (scalar feature) of the geometric vector
            scalar_features.append((geo_vector * ~geo_vector).value[0])  # geo_vector * ~geo_vector gives the norm

        scalar_features = torch.tensor(scalar_features, dtype=torch.float32).unsqueeze(1)  # Make it a 2D tensor
        return scalar_features

# Step 7: GeoClassifier Model
class GeoClassifier(nn.Module):
    def __init__(self, hidden_dim, num_layers):
        super(GeoClassifier, self).__init__()
        self.geo_layer = GeoLayer()
        self.mlp = nn.Sequential(
            nn.Linear(1, 32),  # Single input from GeoLayer
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(16, 2)  # Binary classification (0 or 1)
        )

    def forward(self, positions, rotations):
        # Pass through the GeoLayer
        x = self.geo_layer(positions, rotations)
        # Pass through the MLP
        x = self.mlp(x)
        return x

# Step 8: Initialize model, loss, and optimizer
model = GeoClassifier(hidden_dim=32, num_layers=2)
criterion = nn.CrossEntropyLoss()  # Cross-entropy for binary classification
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_losses = []

# Step 9: Train the model
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        positions_rotations, labels = batch
        optimizer.zero_grad()  # Zero the gradients

        positions = positions_rotations[:, :3]  # First 3 columns are positions
        rotations = positions_rotations[:, 3:]  # Last 3 columns are rotations
        outputs = model(positions, rotations)
        loss = criterion(outputs, labels)

        loss.backward()  # Backward pass
        optimizer.step()  # Update weights

        total_loss += loss.item()  # Accumulate loss
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)

    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}")

# Step 10: Evaluate the model
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for batch in test_loader:
        positions_rotations, labels = batch  # Unpack the data

        # Split the features into positions and rotations
        positions = positions_rotations[:, :3]  # First 3 columns are positions
        rotations = positions_rotations[:, 3:]  # Last 3 columns are rotations

        # Forward pass
        outputs = model(positions, rotations)

        # Get the predicted class
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Test Accuracy: {100 * correct / total:.2f}%")
